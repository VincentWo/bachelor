\chapter{De Rham Cohomology}
To properly understand the phenomena we have seen so far requires us to rephrase them in the language of
differential geometry. Thus we will use this chapter to define the basic vocubalary of differential geometry,
starting with the generalization of differentation to more general domains.


While we are going to aim for a self-contained introduction to all the needed differential geometric
background, it is impossible to do so in our limited format without skipping quite some detail. If one desires a full fledged
introduction (and the topic is definitely more than interesting enough to deserve one), then one should
read one of the plethora of proper ones e.g. \cite{lee_introduction_2013},
\cite{spivak_comprehensive_1979} or \cite{wendl_differential_2022}

\section{Smooth Manifolds}
The usual definition of differentiability only works for open subsets of $\RR^n$, but
we want to generalize the notion to a more general class of spaces known as 
\textit{manifolds}.

Manifolds are a foremost topological concept generalizing the concept of embedded
curves/surfaces one usually encounters in basic analysis courses:
\begin{definition}[Topological Manifold]
A \textbf{Topological Manifold} of dimension $n$ is a metrizable and separable\footnote{
	There are good reasons to require this, but we are just going to accept this as a technical requirement.
}
topological space $M$ in which every point $p \in M$ has a Neighborhood $\U$ that is homeomorphic to
an open set $\V \subseteq \RR^n$.

Given such a set $\U$ and homeomorphism $\varphi: \U \to \V$ we call $(\U, \varphi)$ a \textbf{chart}
or \textbf{local coordinate system} of $M$.
\end{definition}
Thus while a manifold might look globally quite different from $\RR^n$ it is always
going to look like $\RR^n$ locally.

The archetypical example of this concepts are the $n$-spheres, defined as
\[
	S^n \coloneqq \{\, x \in \RR^{n + 1} \mid |x| = 1 \,\}
\]
with $S^1$ more commonly known as the circle. These all look globally quite different
from $\RR^n$, but locally look like $\mathbb{R}^n$, something that becomes evident
every time one uses a navigation app, which usually shows one a projection of some
subset of $S^2$ to a subset of $\RR^2$.

We now want to generalize the notion of differentiability to functions $f: M \to N$,
where $M, N$ aren't open subsets of $\RR^n$, but manifolds. They seem to be perfect
for this purpose since differentiability is a local property anyway and manifolds
locally look like $\RR^n$. 

In fact it does not take long to come up with a definition of differentiability that
seems to work: Given a function $f: M \to N$ between two manifolds we call $f$
differentiable at a point $p \in M$ if there exist local choices of coordinates
$(\U, x)$ around $p$ and $(\V, y)$ around $f(p)$ such that the function
\[
	y \circ f \circ x^{-1}: \mathbb{R}^m \to \mathbb{R}^n
\]
is differentiable. 
 
While this definition might seem quite workable already, it has major flaw:
It is not coordinate independent. That is, given a function is smooth at a
point $p$ with respect to charts $(x, \U)$, $(y, \V)$ there is no guarentee that the function is also going to be
smooth with respect to some other charts $(\tilde{x}, \tilde{\U}), (\tilde{y}, \tilde{\V})$. This can be fixed by
restricting to smooth changes of coordinate, that is by requiring for two charts $(x, \U), (y, \V)$ of some manifold
$m$ that the map $x \circ y^{-1}$ is smooth\footnote{
	Instead of smoothness one can of course also require differentiability,
	but this soon gets messy since some concepts require differentiating more
	than once, so we will be practical and just say smooth, leaving the
	detailed requirements of theorems and definitions as an (not recommened
	unless nescessary) exercise for the reader.
}.

While this is the right choice this requires us to pick more data than just a topological space. We also have to pick
open sets and their coordinate functions.

\begin{definition}
A smooth manifold is a topological manifold with a choice of charts
$\{(\U_\alpha, x_\alpha)\}_{\alpha \in I}$ such that $\bigcup_{\alpha \in I} \U = M$,
and for eny $\alpha, \beta \in I$ the sets $x_\alpha(\U_\alpha \cap \U_\beta$,
$x_\beta(\U_\alpha \cap \U_\beta)$ are open and $x_\alpha \circ x_\beta^{-1}$
is smooth.
\end{definition}
One would hope that it would always be possible to choose charts to turn any given
topological manifold into a smooth one, but by a deep result from differential topology 
this is not always possible. Even worse there are topological manifolds with 
different\footnote{TOOD} choices producing different smooth manifolds, but we mostly
do not have to worry about that.

The word different we used right now 
\begin{definition}
	Let $M,N$ be smooth manifolds. We call a smooth map $f: M \to N$ \textit{diffeomorphism} if it is bijective and
	its inverse is also smooth.
\end{definition}
We call manifolds that admit a diffeomorphism between them diffeomorphic â€“ as in topological spaces it is rather difficult
to show that two spaces are not diffeomorphic, but smooth invariants helps with this.

While we defined smoothness itself, it remains to define the actual derivative of a 
function. This turn out to be a bit more involved since the classical derivative
is dependend on the possibility to talk about directions in a point $p$. That
is given a point $p \in \mathbb{R}^n$ we can talk about the space of all
directions at $p$, a $n$-dimensional vector space that we are going to denote as
$T_p \RR^n$. The derivative of a smooth function $\RR^n \to \RR$ at a point $p$
is then a linear function from $T_p \RR^n$ to $\RR$. We call $T_p \RR^n$ the 
tangent space at $p$.

This is not completely straightforward to translate to an abstract smooth manifold
since in general there do not exists any canonical directions on a manifold. But
fixing a choice of chart $x: M \to \RR^n$ around $p \in M$  we can represent the
directions at $x(p)$ using the directions at $p$, defining 
\[
	T_p^x M \coloneqq T_{x(p)} M
\]
Similiar to how we can change coordinates on $M$ by $y \circ x^{-1}$, we can also
switch from one choice of directions to another by using the isomorphism:
\[
	D(y \circ x^{-1})(x(p)): T^x_p M = T_{x(p)} \RR^n \to T_{y(p)} \RR^n = T^y_{y(p)} M
\]
Thus one can define $T_p M$ as the union of all $T^x_p M$ for any chart $x$ modulo
the equivalence relation equating two vectors $a \in T^x_p M$ and $b \in T^y_p$
if and only if $b = D(y \circ x^{-1})(p)(a)$.

For any chart $x$ at $p$ there is a canonical choice of projection
$\pi^x: T_p M \to T_p^x M$ and we can turn $T_p M$ into a vector space such that each
of this projections is an isomorphism.

Then given a map $f: M \to N$ we may define its derivative as the linear map
\[
	T_pf: T_p M \to T_{f(p)}N = (\pi^y)^{-1} \circ D(y^{-1} \circ f \circ x)(p) \circ \pi^x
\]

$T \RR^n$ has a canonical basis and thus every $T_p^x M$ has a canonical basis, this
can be used to associate a basis of $T_p M$ for a choice of local coordinates $x$,
which we are going to denote as
$\frac{\partial}{\partial x^1}, \dots, \frac{\partial}{\partial x^n}$.

We sadly do not have the time to fully develop the theory of tangent spaces, which is
why are going to have to take some remaining things as black bloxes. One can
take the disjoint union of all tangent spaces to define the tangent bundle
$TM \coloneqq \bigcup_{p \in M} T_p M$. This can then be equipped with a smooth
manifold structure of dimension $2n$. Then $Tf: TM \to TN$ can be defined in the
obvious way to match every $T_p f$

\section{Differential Forms}
Conviently this concept of signed area is not a new thing, one recalls from linear algebra that
the determinant of a $n \times n$ matrix can be interpreted as the signed change of area of a
$n$ parallelopiped under the linear transformation. And indeed, our theory of differential
forms is going to start with its linear algebraic predecessor: Forms, which we are going
to use to define the concept of a "weighted" $n$-volume of a $n$-parallelopiped. This concept
can then by generalized to smooth manifolds by using tangent spaces as local linearizations
of a smooth manifolds, allowing us to talk rigourisly about "infinitisimal" volumes without
having to take limits. After that we finally are going to be able to enjoy the fruits of our
labor by defining de Rham cohomology and developing its basic computational tools.

\begin{remark}
The power of differential geometry often lies in using the (hopefully)
familiar techniques of linear algebra to analyse smooth functions
% 
\end{remark}

% TODO: The upper section is kind of ugly
\subsection*{Forms}
% TODO: Pullback of forms
When defining integration one usually starts to talk about "infinitisimal"
displacements (or in higher dimensions parallelepipeds), making everything
precise using limits. But we already have a way to talk about an "infinititisimal"
change in a direction: The tangent space at a point precisely presents that.

Because of this logic it makes sense to start the definition of differential forms
as a locally defined function on the tangent space. Also: One important property of
smooth objects is that they are "locally linear", hence it might even be enough to
limit ourselves to linear maps of the tangent space.

We therefore define a differential 1-form at a point $p$ to be a linear map from
$T_pM$ to $\RR$.

This logic upholds for line-integrals quite well, but is there any way to use the
tangent space to represent higher dimensional shapes? Since we can't assume there
% TODO: Talk about determinant
to be any canonical definition of matrix, we have to limit ourselves to shapes that
can be defined just using the linear algebraic properties of the tangent space. The
most obvious shape is therefore the $k$-parallelepiped, that we can represent using
an $k$-tuple of vectors $\xi_1, \dots, \xi_k \in T_pM$. Following the linearity of 
the 1-dimensional case, we also require a differential $k$-form to be linear in all
its arguments. For $k \geq 2$ there is also a special class of parallelepipeds,
the degenerate ones which have two or more linear dependent sides. These don't have
any $k$-volume and hence we require our differential forms to map these to zero.
One consequence of this is that for any $\xi_1, \xi_2 \in \RR^n$ we have:
\begin{align*}
&&	 0 &= \omega(\xi + \eta, \xi + \eta) \\
&&	   &= \omega(\xi, \xi + \eta) + \omega(\eta, \xi + \eta) \\
&&	   &= \underbrace{\omega(\xi, \xi)}_{= 0} + \omega(\xi, \eta) + \omega(\eta, \xi) + \underbrace{\omega(\eta, \eta)}_{= 0} \\
&&	   &= \omega(\xi, \eta) + \omega(\eta, \xi) \\
&\iff& \omega(\xi,\eta) &= - \omega(\eta,\xi)
\end{align*}
hence we require differential forms to be skew-symmetric. In fact skew-symmetry is
not only a necessary, but also a sufficient condition for forms to map linear
dependent vectors to zero.
\begin{lemma}
	Let $\omega$ be a skew-symmetric $k$-form on $\RR^n$ and $\xi_1, \dots, \xi_k$
	be lineary dependent. Then $\omega(\xi_1, \dots, \xi_k) = 0$
\end{lemma}
\begin{proof}
	Without loss of generality we assume that $\xi_1 = \lambda_2 \xi_2 + \dots + \lambda_k \xi_k$
	for some $\lambda_2, \dots, \lambda_k \in \RR$. Then:
	\begin{align*}
		\omega(\xi_1, \dots, \xi_n)
		&=
		\omega(\lambda_2 \xi_2 + \dots + \lambda_k \xi_k, \xi_2, \dots, \xi_k) \\
		&=
		\lambda_2 \omega(\xi_2, \xi_2, \dots, \xi_k) + \dots + \lambda_k \omega(\xi_k, \xi_2, \dots, \xi_k)
	\end{align*}
	All of these terms have at least two equal vectors and hence by skew-symmetry are equal to their
	negative value, which is only possible if they are zero. Therefore the sum is zero.
\end{proof}
This effort culminates in our local definition of a differential form:
\begin{definition}
Let $M$ be a smooth $n$-manifold and $p \in M$. A $k$-differential form (with $k \leq n$)
at $p$ is a skew-symmetric multi-linear map from $(T_p M)^k$ to $\RR$.
\end{definition}

Now some notation. Given a basis $\frac{\partial}{\partial x_1}, \dots, \frac{\partial}{\partial x_n}$
of a tangent space $T_p M$, we denote the dual basis as $\mathrm{d}x_1, \dots, \mathrm{d}x_n$, i.e.:
\[
	\mathrm{d}x_i(\frac{\partial}{\partial x_j}) = \delta_{i,j}
\]
We then recall from linear algebra that every linear map $\omega$ can be uniquely written as:
\[
	\omega = c^i \mathrm{d}x_i	
\]
for $c^1, \dots, c^n \in \RR$, so we usually denote differential forms like that
(but always remember that this is a non-canonical, coordinate dependent notation).

We can add more structure to this. 


Let's imagine that we have two differential forms $\mathrm{d}x_1$ and $\mathrm{d}x_2$.
Both of these assign a "weight" to the $\frac{\partial}{\partial  x_1}$/$\frac{\partial}{\partial x_2}$ direction,
so there should be a way to assign a "matching" weight to the parallelogram spanned by these vectors.
In fact we will denote this 2-form as $\mathrm{d}x_1 \wedge \mathrm{d}x_2$

TODO: k-forms representation, smoothness, exterior product, definition of integration

\subsection{The exterior deriative}
One of the most important aspects of integration on $\RR$ is the
fundamental theorem of calculus:
\[
	\int_a^b f'(t)\mathrm{d}t = f(b) - f(a)	
\]
To generalize this to higher dimensions we first note that the points $a,b$ are the
boundary of the path from $a$ to $b$. Points can be taken as 0-dimensional manifolds
and hence the concept of induced boundary notation can be extended to them, in absence
of different orders of a single point we take the order of a point to be either a plus
or minus sign. Hence the path from $a$ to $b$ induces a positive orientation on $b$
and a negative one on $a$, equal to the signs in the fundamental theorem. Even
going further we can define the integration of a smooth function $f$ on a 0-dimensional
oriented manifold $M$ as:
$
	\int_M f = \sum_{p \in M} \sign(p) f(p)
$
where $\sign(p)$ represents the orientation of $p$. This allows us to rephrase the
fundamental theorem as a statement purely about integration:
\[
	\int_a^b f'(t)\mathrm{d}t = \int_{\{-a, b\}} f
\]
since a differential $k$-form can be integrated on $k$-manifolds, we are going to
call smooth functions differential $0$-forms.

The fundamental theorem of calculus in 1-dimension fits in the picture of differential
forms as a measurement of change. Given a $0$-form $f$ on points, the integral of the
one form $f'$ on a path $\gamma$ from $a$ to $b$ measures the total change of $f$
on that path. Generalizing this we ask whether for a given $k$-form $\omega$ there
is a $k + 1$-form $\eta$ such that for every $k+1$-manifold $M$ we have:
\[
	\int_M \eta = \int_{\partial M} \omega
\]
\section{De Rham Cohomology}
After this introduction to the basic of differential geometry we now have enough
tools in our toolbox to define de Rham cohomology, which is going to be our main
focus of study.

We start by recapping some of the introduction: There we started exploring the connection between
locally constant functions and the connected components. Locally constant functions are exactly the
zero forms with vanishing derivative, that is:
\begin{align*}
	H^0_\dr \coloneqq \Omega^0(M) \cap \ker(\rmd)
\end{align*}
We are going to call this \textit{the zeroth de Rham cohomology of $M$}. As the kernel of a linear map this is a
vector space, which dimension can easily seen to be equal to the number of connected components of $M$.

At this time it might be tempting to define the de Rham cohomology just as the kernel of $\rmd$, but that this
works in dimension zero is just a happy little accident â€“ one sees that by considering our next case: The
conservativity of vector fields. In the introduction we talked about an interconnection between a space being
simple connected and the existence of non-conservative vector fields with vanishing curl. Originally we defined a
vector field $f$ on $\RR^3$ as just a map from $\RR^3$ to $\RR^3$. One can turn such a vector field into a
differential 1-form as follows:
\begin{align*}
	\omega = f_1 \dx{1} + f_2 \dx{2} + f_3 \dx{3}
\end{align*}
We can calculate the exterior derivative of this vector field:
\begin{align*}
	\rmd \omega &=
		  \left(\pdx[f_1]{2} \right) \dx{2}\dx{1}
		+ \left(\pdx[f_1]{3} \right) \dx{3}\dx{1}
		+ \left(\pdx[f_2]{1} \right) \dx{1}\dx{2}
		+ \left(\pdx[f_2]{3} \right) \dx{3}\dx{2} \\
		&\phantom{=}\,+ \left(\pdx{1} f_3\right) \dx{1}\dx{3}
		+ \left(\pdx{2} f_3\right) \dx{2}\dx{3} \\
		&= \left( \pdx[f_2]{1} - \pdx[f_1]{2} \right) \dx{1}\dx{2}
			+ \left( \pdx[f_3]{2} - \pdx[f_2]{3} \right) \dx{2}\dx{3} \\
		&\phantom{=}\,+ \left( \pdx[f_1]{3} - \pdx[f_3]{1} \right) \dx{3}\dx{1}
\end{align*}
This vanishes if and only if the curl of $f$ vanishes, hence we are once against interested in the kernel of $\rmd$,
but we also want to conclude the "boring" cases, where $f$ is actually conservative. These are the cases where
there is a potential $F$ with derivative $\nabla F = f$. But taking the vector fields with curl as a 1-form one
may rephrase this as there being a 0-form $F$ such that $\rmd F = \omega$.  Thus we are actually interested in
the kernel of $\rmd$ modulo the image of $\rmd$.

None of this prior discussion depended on any special cases, hence we may define:
\begin{definition}
Let $M$ be a smooth manifold. We define the \textbf{de-Rham cohomology of $M$} as the graded
algebra:
\[
	H^*_\dr(M) \coloneqq \bigoplus_{k = 0}^\infty \ker(\mathrm{d}^k)/\Img(\mathrm{d}^{k - 1})
\]
\end{definition}
\begin{remark}
Elements of $H^*(M)$ are equivalence classes of elements of $\Omega^*(M)$, which we will
denote as $[c]$ for some $c \in \Omega^*(M)$ as a representative. But since we are going to
talk a lot about cohomology we are going to sometimes abuse notation and write $c$ to mean $[c]$
when the intent is clear. One just has to remember that the cohomology consists of equivalence classes
and that hence such a choice is not unique in general.
\end{remark}

Because of the way we defined de Rham cohomology we can already make some harmless sounding statements, that are
going to turn out quite usefull:
\begin{lemma}
Let $M$ be a smooth $n$-manifold. Then for every $k > n$:
\[
	H^k_\dr(M) = 0
\]
\end{lemma}
\begin{proof}
For $k > n$ the only skew-symmetric $k$-form on a $n$-dimensional vector space is $0$, hence
$\Omega^k(M) = 0$, which implies $H^k(M) = 0$.
\end{proof}.

It is instructive to do some cohomology calculations:
\begin{lemma}[PoincarÃ© lemma]
	The de Rham cohomology of $\RR^n$ is:
	\begin{align*}
		H^k_\dr(\RR^n) = \begin{cases}
			\RR &\quad\text{if } k = 0 \\
			0   &\quad\text{otherwise}
		\end{cases}
	\end{align*}
\end{lemma}
\begin{proof}
We are going to prove this by induction. For $\RR^0$ we have $H^0_\dr(\RR) = \RR$ since $\RR$ is connected
and $H^k_\dr(\RR) = 0$ for $k > 0$ since $\RR^0$ is zero-dimensional.

We now want to prove that $H^k(\RR^n \times \RR) \cong H^k(\RR^n)$. Let
$\omega \in \Omega^*(\RR^n \times \RR)$ such that $\rmd \omega = 0$, then one can write $\omega$ as:
\begin{align*}
	\omega = \sum f_I \dx{I} + \sum g_I\dx{I}\dx{n + 1}
\end{align*}
We can now use a technique called integration over fibers, which is a fancy word for using the fundamental 
theorem of calculus by defining:
\begin{align*}
	\Psi(x_1, \dots, x_n, x_{n + 1}) = \sum \left(\int_0^{x_{n + 1}} g_I(x_1, \dots, x_n, t) \rmd t \right) \dx{I}
\end{align*}
Thus we have:
\begin{align*}
	\rmd \Psi = \sum_{i \in } \pdx{i} \left(\int_0^{x_{n + 1}} g_I(x_1, \dots, x_n, t) \rmd t \right) \dx{i}\dx{I}
\end{align*}
\end{proof}
\subsection{The Mayer-Vietoris Sequence}
With our current knowledge it seems impossible to calculate the de-Rham cohomology for anything but the most simplest of
spaces, hence we have to develop more computational tools. We are going to start with the most important one: A way to
calculate the cohomology of more complicated spaces by splitting them into simpler ones, whose cohomology is known.
Concretely we are going to find a connection between the cohomology of a space $X$ and the cohomology of open subsets $\U, \V$ that cover $X$
i.e. $\U \cup \V = X$.

That connection is going to be the \textbf{Mayer-Vietoris-Sequence}, derived from the sequence of inclusions:
\begin{center}
% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAFkQBfU9TXfIRQBGclVqMWbADrSAqgAJZAYwhoATtCXSAat14gM2PASIAmMdXrNWiELMUq6abXq7iYUAObwioAGaaALZIFiA4EEiiIAxYYLYgcBCxUCDUABYwdKmIYEwMDNQ4dFgMbJDxaYnpWP44SAC00dZSdlgA+rJuBoEQIYhhEVHUcDV1wzF0AEYwDAAK-CZCIOpYXun1VpIJHQ76AcETQ4hkEjZsAFbcFFxAA
\begin{tikzcd}
M & \U \coprod \V \arrow[l, "j"] & \U \cap \V \arrow[l, "i_\V", shift left] \arrow[l, "i_\U"', shift right]
\end{tikzcd}
\end{center}
With $\U \coprod \V$ being the disjoint union, $j$ the inclusion from $\U$ and $\V$ into $M$
and $i_\U$ being the inclusion of $\U \cap \V$ into $\U$ (and then into the disjoint union),
similiar with $i_\V$. All of these are smooth maps and hence this induces another sequence of
restrictions of differential forms:
\begin{equation}
% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12B5AWxgHM6APQBUACgCyAShABfUuky58hFAEZyVWoxZtOvAcPGcAqlIAEnAEZZ+ENMziXufQaLGcAajPmLseAiIAJk1qemZWRA4XQ3dTZwBjOjRnbzktGCh+eCJQADMAJwgeJA0QHAgkEJAGLDBIkDgIWqgQagALGDpWxDAmBgZqHDosBjZIerbG9qw8nFKwnQasAH0vUSmGOisYBgAFJQDVEALbdvnfEELihfLKxGq4GbmkAFoyrZ39w5U2BhgXosImxVqYNpdriVEGQ7rdwroogArcEUWRAA
\begin{tikzcd}
\Omega^*(M) \arrow[r, "j^*"] & \Omega^*(\U) \bigoplus \Omega^*(\V) \arrow[r, "i_\V^*"', shift right] \arrow[r, "i_\U^*", shift left] & \Omega^*(\U \cap \V)
\end{tikzcd}
\label{cd:de-rham:mv-first}
\end{equation}
This does not quite get us anywhere, but we recall from (linear) Algebra that there are special
kind of sequences that provide a lot of information:
\begin{definition}
Let $A_i$ a sequence of vector spaces with homomorphism $f_i: A_i \to A_{i + 1}$:
\begin{center}
	% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12oIcEBfUuky58hFAEZyVWoxZsAggH1gAawAEAWjXi+IAUOx4CRAExTq9Zq0Qglq3fpAZDoogGZzMqwuXqA1NoOgk7CRmLIACyelnI2nNy8etIwUADm8ESgAGYAThAAtkiSIDgQSCaOuQXl1KVIbpV5hYgeJWWIEY3ViGRtRXwUfEA
	\begin{tikzcd}
	\dots \arrow[r] & A_{k - 1} \arrow[r] & A_{k} \arrow[r] & A_{k + 1} \arrow[r] & \dots
	\end{tikzcd}
\end{center}
We call this sequence \textbf{exact} if $\Img(f_i) = \ker(f_{i + 1})$ for every $i \in \NN$.
If every $A_i$ but three are zero we call it a \textbf{short exact sequence}.
\end{definition}
Now \ref{cd:de-rham:mv-first} being exact can be seen as the statement that
the cohomology of a space is the cohomology of its parts, modulo their overlap.

This statement seems reasonable, but we have to modify it a bit, since the default restrictions would map a form $\omega$ on $M$
to the form $2\omega$ on $\U \cap \V$ which of course does not have to be zero. But we can make this nilpotent by arrigning some signs to arrive at the 
\textbf{Short Mayer Vietoris Sequence}:
\begin{equation}
	% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQAdDgeQFsYA5vQB6AKgAUAWQCUIAL6l0mXPkIoATBWp0mrdlz6CRErgFVpAAi4AjLAIhoWcKz35Cx4rgDVZCpdjwCIgBmLRoGFjZETlcjDzMXAGN6NBcfeUUQDADVInIwnUj2cgz-FSCUABYCiL1okr8s5UC1ZE1ibVqokE8OCDd6UhccemZfTOzy1tCO8N1urhHmCwBaF36jeW0YKAF4IlAAMwAnfqQyEBwIJE0QRiwwbrgIe6gQGgALGHo3xDBmRiMGgjLCMdiQR7vEBwD5YQ44JD5Qp1EBYMQAfW8qwsaNEmI4pihjHo1hgjAACs1ctFGDB4aUQCczogkVdznMitEAFZiBlM3hIUKXa4sxr8m7AkWVMWnAWIACskqQADZgfRQexeCk4Gy5JQ5EA
	\begin{tikzcd}
	0 \arrow[r] & \Omega^*(M) \arrow[r, "j^*"] & \Omega^*(\U) \bigoplus \Omega^*(\V) \arrow[r, "i^*_\V - i^*_\U"] & \Omega^*(\U \cap \V) \arrow[r] & 0 \\
	            &                              & {(\omega, \tau)} \arrow[r, maps to]                              & \tau - \omega                  &  
	\end{tikzcd}
	\label{cd:de-rham:mv-ses}
\end{equation}
Now the important statement becomes:
\begin{theorem}
The Short Mayer-Vietoris sequence (\ref{cd:de-rham:mv-ses}) is exact.
\end{theorem}
%TODO: I need to talk about partitions of unity somewhere
\begin{proof}
We already concluded that $j^*$ is injective and the kernel of $i^*_\V - i^*_\U$ consists
exactly of the differential forms that agree on $\U \cap \V$, hence
$\Img(j^*) = \ker(i^*_\V - i^*_\U)$.

It remains to show that $i^*_\V - i^*_\U$ is surjective, which we are going to do by
constructing a right-inverse. Let $\omega \in \Omega^*(\U \cap \V)$ and $\rho_\U, \rho_V$ a
partition of unity subordinate to $\U, \V$. Now $\rho_\mathcal{V} \omega$ (taken as pointwise
multiplication) can be zero-extended to $\U$, as can $\rho_\mathcal{U} \omega$ to $\V$. We then
have:
\begin{equation*}
	(i^*_\V - i^*_U)(-\rho_\V \omega, \rho_\U \omega) = (\rho_\U + \rho_\V)\omega = \omega
\end{equation*}
Therefore this map is surjective and the whole sequence is exact.
%TODO: Picture
\end{proof}
This is still a bit pointless since it is only a statement of differential complexes, not of
cohomologies. But all of these maps descend to maps on cohomlogies
\begin{theorem}[Mayer-Vietoris sequence]
	Let $M$ be a smooth manifold and $\U, \V$ open subsets, such that $M = \U \cup \V$.

	The short Mayer-Vietoris sequence
	\begin{equation*}
	% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12B5AWxgHM6APQBUACgCyAShABfUuky58hFAEZyVWoxZtOvAcPGcAqlIAEnAEZZ+ENMziXufQaLGcAajPmLseAiIAJk1qemZWRA4XQ3dTZwBjOjRnbzktGCh+eCJQADMAJwgeJA0QHAgkEJAGLDBIkDgIWqgQagALGDpWxDAmBgZqHDosBjZIerbG9qw8nFKwnQasAH0vUSmGOisYBgAFJQDVEALbdvnfEELihfLKxGq4GbmkAFoyrZ39w5U2BhgXosImxVqYNpdriVEGQ7rdwroogArcEUWRAA
	\begin{tikzcd}
	\Omega^*(M) \arrow[r, "j^*"] & \Omega^*(\U) \bigoplus \Omega^*(\V) \arrow[r, "i_\V^*"', shift right] \arrow[r, "i_\U^*", shift left] & \Omega^*(\U \cap \V)
	\end{tikzcd}
	\end{equation*}
	induces a long exact sequence sequence in cohomology, called \textbf{Mayer-Vietoris} sequence:
	\begin{equation}
		% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQAJAPQGsAKALIBKEAF9S6TLnyEUAJgrU6TVu278AOhoCqQgARaARlgDmENCzh71fLQDUR4ydjwEiAZkU0GLNok68tjoGGgDG9GghDmISIBguMkTkXsq+7FpQEDgITnFSrrIkpMRKPqr+3MA8egDUesSigo6x8dJu8sWlKn4BVbX1jVq6IcZmFsxWldV1DUHRua0FHp3e3WpcfTODwVrhkfbNzm2FACwrqeUgGVk5SjBQJvBEoABmAE4QALZIZCA4EEgFCBGFgwD04BAQVAQDQABYwejQxBgZiMRg0HD0LCMdiQMEwkBwWFYF44JDJYH0QwwRgABXyiX8jBgpJirw+30QFP+P1y7y+SE8fwBXL5HKQADYMSKAOxigWIM7CpAAVnlnJV0slokooiAA
		\begin{tikzcd}[column sep=small]
			\usetikzlibrary{fadings}
			&\arrow[
				d,
				"\dots"{description},
				dash pattern=
					on 0.5pt
					off 8pt
					on 1pt
					off 7pt
					on 2pt
					off 6pt
					on 4pt
					off 5pt
					on 6pt
					off 4pt
					% on 8pt
					% off 3pt
					% on 10pt
					% off 1pt
					on 100pt,
				rounded corners,
				to path={
					([xshift=3ex]\tikztostart.west)
					-- (\tikztostart.west)
					-- ([xshift=-3ex]\tikztostart.west)
					-| ([xshift=-3ex]\tikztotarget.west)
					-- (\tikztotarget)
				}
				]
			&\\[-1.6em]
			& H^k(M)
				\arrow[r]
			& H^k(\U) \bigoplus H^k(\V)
				\arrow[r]
				% \arrow[u, ""{coordinate, name=U}]
				\arrow[d, phantom, ""{coordinate, name=Z}]
			& H^k(\U \cap \V)
				\arrow[
					dll,
					"d^*"{pos=1.0, description},
					rounded corners,
					to path={
						-- ([xshift=2ex]\tikztostart.east)
						|- (Z) [near end]\tikztonodes
						-| ([xshift=-2ex]\tikztotarget.west)
						-- (\tikztotarget)
					}]
			&\\
            & H^{k + 1}(M)
				\arrow[r]
			& H^{k + 1}(\U) \bigoplus H^{k + 1}(\V)
				\arrow[d, phantom, ""{coordinate, name=D}]
				\arrow[r]
			& H^{k + 1}(\U \cap \V)
				\arrow[
					d,
					""{description},
					dash,
					dash pattern=
						on 0.5pt
						off 8pt
						on 1pt
						off 7pt
						on 2pt
						off 6pt
						on 4pt
						off 5pt
						on 6pt
						off 4pt
						% on 8pt
						% off 3pt
						% on 10pt
						% off 1pt
						on 100pt,
					rounded corners,
					to path={
						([xshift=-6ex]\tikztotarget.east)
						-| ([xshift=2ex]\tikztostart.east)
						-- (\tikztostart.east)
					}
				]
			&\\[-1.3em]
			& {} & {} & {}
		\end{tikzcd}
	\end{equation}
\end{theorem}
The easiest way to prove this is to actually first prove a much more abstract algebraic result,
which is going to include our theorem as a special case. But before we can do this we have to
define some algebraic basics.
\begin{definition}[Cochain Complex]
A \textbf{cochain complex} is a graded vector space $A^*$ together with maps
\begin{align*}
	\rmd^k: A^k \to A^{k + 1}
\end{align*}
which together define a map $\rmd: A^* \to A^*$ in the obvious way, that fullfills:
\begin{align*}
	\rmd \circ \rmd = 0
\end{align*}
The map $\mathrm{d}$ will usually be called \textbf{differential} or
\textbf{coboundary operator} of $A^*$.
\end{definition}
The de Rham complex is our most important example of cochain complex. We can even phrase
the concept of Cohomology in purely algebraic terms:
\begin{definition}[Cohomology]
Let $A^*$ be a cochain complex. We define the \textbf{cohomology} of $A^*$ as the graded
vector space:
\begin{align*}
H^k(A^*) \coloneqq \ker(\rmd^k) / \Img(\rmd^{k - 1})
\end{align*}
We will call $\ker(\rmd^k)$ $k$-cocyles of $A^*$ and $\Img(\rmd^{k - 1})$
$k$-coboundaries of $A^*$.
\end{definition}
The only missing ingredients remaining to give the more general result is a general way to
talk about maps between cochain complexes
\begin{definition}[cochain map]
Let $(A^*, \rmd_A^*), (B^*, \rmd_B^*)$ be cochain complexes and $f^k: A^k \to B^k$ a vector
space homomorphism for every $k$. We call $f^k$ \textbf{cochain map} if it commutes with
$\rmd_A^*$/$\rmd_B^*$ i.e. if the following diagram commutes:
\[\begin{tikzcd}
	{A^*} & {A^{* + 1}} \\
	{B^*} & {B^{* + 1}}
	\arrow["{\mathrm{d}_A}", from=1-1, to=1-2]
	\arrow["{f^*}"', from=1-1, to=2-1]
	\arrow["{f^{* + 1}}"', from=1-2, to=2-2]
	\arrow["{\mathrm{d}_B}"', from=2-1, to=2-2]
\end{tikzcd}\]
(this introduces a common abuse of notation: Writing $A^*, A^{* + 1}$ to mean that these can be
replaced by $A^k, A^{k + 1}$ for any $k$.
)
\end{definition}
Cochain maps are so important because they induce well-defined maps in cohomology:
\begin{lemma}
Let $(A^*, \rmd_A), (B^*, \rmd_B)$ be two cochain complexes and $f^*: A^* \to B^*$ be a chain
map. Then the homomorphism $\tilde{f}^*: H^*(A^*) \to H^*(B^*)$ is well-defined.
\end{lemma}
\begin{proof}
$f^*$ descends to a map $\tilde{f}^*$ on $H^*(A^*)$ since this is just a quotient of a
subspace of $A^*$. It remains to check that $\Img(\tilde{f}^*) \subseteq H^*(B^*)$. Let
$a \in \ker(\rmd_A)$, then:
\begin{align*}
\rmd_B(\tilde{f}^*(a)) = \tilde{f}^*(\rmd_A a) = 0
\end{align*}
Hence $\Img(\tilde{f}^*) \subseteq H^*(B^*)$.
\end{proof}
By abuse of notation we will usually refer to $f^*$ and $\tilde{f}^*$ as just $f^*$.

By replacing vector spaces with cochain complexes and maps with cochain complexes we can
talk about a short exact sequence of cochain complexes and thus finally phrase our general
statement:
\begin{theorem}
Let
% https://q.uiver.app/#q=WzAsNSxbMSwwLCJBXioiXSxbMCwwLCIwIl0sWzIsMCwiQl4qIl0sWzMsMCwiQ14qIl0sWzQsMCwiMCJdLFsxLDBdLFswLDIsImZeKiJdLFsyLDMsImdeKiJdLFszLDRdXQ==
\[\begin{tikzcd}
	0 & {A^*} & {B^*} & {C^*} & 0
	\arrow[from=1-1, to=1-2]
	\arrow["{f^*}", from=1-2, to=1-3]
	\arrow["{g^*}", from=1-3, to=1-4]
	\arrow[from=1-4, to=1-5]
\end{tikzcd}\]
be a short exact sequence of chain complexes. Then there exists a connecting morphism
$\rmd^*: C^* \to A^{* + 1}$ such that the sequence
% https://q.uiver.app/#q=WzAsNixbMSwwLCJIXiooQV4qKSJdLFsyLDAsIkheKihCXiopIl0sWzMsMCwiSF4qKENeKikiXSxbNCwwLCJIXnsqICsgMX0oQV4qKSJdLFs1LDAsIlxcZG90cyJdLFswLDAsIlxcZG90cyJdLFswLDEsImZeKiJdLFsxLDIsImdeKiJdLFsyLDMsIlxcbWF0aHJte2R9XioiXSxbMyw0XSxbNSwwXV0=
\[\begin{tikzcd}[column sep=small]
	\dots & {H^*(A^*)} & {H^*(B^*)} & {H^*(C^*)} & {H^{* + 1}(A^*)} & \dots
	\arrow[from=1-1, to=1-2]
	\arrow["{f^*}", from=1-2, to=1-3]
	\arrow["{g^*}", from=1-3, to=1-4]
	\arrow["{\mathrm{d}^*}", from=1-4, to=1-5]
	\arrow[from=1-5, to=1-6]
\end{tikzcd}\]
is exact.
\end{theorem}
\begin{proof}
We first define a candidate for the morphism, then prove that it is well-defined and then,
that it indeed makes the sequence exact. Let $[c] \in H^k(C^*)$. $g^k$ is surjective, hence
we can pick a $b \in B^k$ such that $g^k(b) = c$. Since $g^*$ is a cochain map we can put
these in a commutative diagram together with $\mathrm{d}_B b$ and $\rmd_C c$ (which is by
definition zero):
% https://q.uiver.app/#q=WzAsNCxbMCwwLCJiIl0sWzAsMSwiXFxtYXRocm17ZH1fQiBiIl0sWzEsMSwiMCJdLFsxLDAsImMiXSxbMCwxLCJcXG1hdGhybXtkfV9CIiwyXSxbMSwyLCJnXntrICsgMX0iXSxbMCwzLCJnXmsiLDJdLFszLDIsIlxcbWF0aHJte2R9X0MiXV0=
\[\begin{tikzcd}[column sep=small]
	b & c \\
	{\mathrm{d}_B b} & 0
	\arrow["{g^k}"', from=1-1, to=1-2]
	\arrow["{\mathrm{d}_B}"', from=1-1, to=2-1]
	\arrow["{\mathrm{d}_C}", from=1-2, to=2-2]
	\arrow["{g^{k + 1}}", from=2-1, to=2-2]
\end{tikzcd}\]
Thus $g(\mathrm{d}_B b) = 0$ and by exactness there is a $a \in A^{k + 1}$ such that 
$f(a) = \rmd_B b$. We define the connecting map as the map from $[c]$ to $[a]$.

There was one choice we made in this construction: Picking a specific $b$ (picking $a$ did not
involve a choice since $f^*$ is injective on the cochain complexes). To prove that that $[a]$
is independent of this choice let $\tilde{b} \in B^k$ be another element such that
$g^k(\tilde{b})=c$. Then $g^k(b - \tilde{b}) = 0$ and thus their exists a $\hat{a} \in A^k$
such that $f^k(a) = b - \tilde{b}$ and thus by commutatitivy:
% https://q.uiver.app/#q=WzAsNixbMSwwLCJiIC0gXFx0aWxkZXtifSJdLFsxLDEsIlxcbWF0aHJte2R9X0IoYiAtIFxcdGlsZGV7Yn0pIl0sWzIsMSwiMCJdLFsyLDAsIjAiXSxbMCwwLCJcXGhhdHthfSJdLFswLDEsIlxcbWF0aHJte2R9X0FcXGhhdHthfSJdLFswLDEsIlxcbWF0aHJte2R9X0IiLDJdLFsxLDIsImdee2sgKyAxfSIsMl0sWzAsMywiZ15rIl0sWzMsMiwiXFxtYXRocm17ZH1fQyJdLFs0LDAsImZeayJdLFs0LDUsIlxcbWF0aHJte2R9X0EiLDJdLFs1LDEsImZee2sgKyAxfSIsMl1d
\[\begin{tikzcd}[column sep=small]
	{\hat{a}} & {b - \tilde{b}} & 0 \\
	{\mathrm{d}_A\hat{a}} & {\mathrm{d}_B(b - \tilde{b})} & 0
	\arrow["{f^k}", from=1-1, to=1-2]
	\arrow["{\mathrm{d}_A}"', from=1-1, to=2-1]
	\arrow["{g^k}", from=1-2, to=1-3]
	\arrow["{\mathrm{d}_B}"', from=1-2, to=2-2]
	\arrow["{\mathrm{d}_C}", from=1-3, to=2-3]
	\arrow["{f^{k + 1}}"', from=2-1, to=2-2]
	\arrow["{g^{k + 1}}"', from=2-2, to=2-3]
\end{tikzcd}\]
And since $[\rmd_A] = 0$ by definition, both $b$ and $\tilde{b}$ lead to the same $[a]$, hence
$\mathrm{d}^*$ is well-defined.

Proof of exactness starts with proving that $\Img(f^k) = \ker(g^k)$ in cohomology. One part of
this is trivial:
\begin{align*}
	(g \circ f)([a]) = [(g \circ f)(a)] = [0] = 0
\end{align*}
For the reverse let $[b] \in H^k(B^*)$ such that $g^k([b]) = [0]$. That is the case if and only if
$g^k(b) = \rmd_C c$ for some $c \in C^{k - 1}$. By surjectivity there is then a
$\hat{b} \in B^{k - 1}$ such that $g^{k - 1}(\hat{b}) = c$. By commutativity then
$g(\rmd_B \hat{b}) = \rmd_C g(\hat{b}) = \rmd_C c$ and thus $g^k(b - \rmd_B \hat{b}) = 0$.
By exactness of the original sequence there exists therefore a $a \in A^k$ such that
$f^k(a) = b - \rmd_B \hat{b}$ and:
\begin{align*}
	0 = \rmd_B (b - \rmd_B \hat{b}) = \rmd_B f^k(a) = f^{k + 1}(\rmd_A a)
\end{align*}
Hence by injectivity $\rmd_A a = 0$ and thus $[a] \in H^k(A^*)$. Especially:
\begin{align*}
	f^k([a]) = [b - \rmd_B \hat{b}] = [b] - [\rmd_B \hat{b}] = [b]
\end{align*}
Hence $\Img(f^k) = \ker(g^k)$.

Next we prove that $\Img(g^k) = \ker(\rmd^*)$. Let $[b] \in H^k(B^*)$, looking at our
construction of $\rmd^*$ we see that $\rmd_B b = 0$ and hence $a = 0$ by injectivity
and hence $\rmd^* [g^k(b)] = [a] = 0$ and $\ker(\rmd^*) \subseteq \Img(g^*)$. Also, if $\mathrm{d}^* [c] = [0]$, then our
construction becomes:
% https://q.uiver.app/#q=WzAsNSxbMCwxLCJcXG1hdGhybXtkfV9BIGEiXSxbMCwwLCJhIl0sWzEsMSwiXFxtYXRocm17ZH1fQiBiIl0sWzEsMCwiYiJdLFsyLDAsImMiXSxbMSwwLCJcXG1hdGhybXtkfV9BIiwyXSxbMCwyLCJmXntrICsgMX0iLDJdLFszLDIsIlxcbWF0aHJte2R9X0IiXSxbMyw0LCJnXmsiXV0=
\[\begin{tikzcd}
	a & b & c \\
	{\mathrm{d}_A a} & {\mathrm{d}_B b}
	\arrow["{\mathrm{d}_A}"', from=1-1, to=2-1]
	\arrow["{g^k}", from=1-2, to=1-3]
	\arrow["{\mathrm{d}_B}", from=1-2, to=2-2]
	\arrow["{f^{k + 1}}"', from=2-1, to=2-2]
\end{tikzcd}\]
Since $g^k \circ f^k = 0$ it follows that $g^k(b - f^k(a)) = c$ and since $f^*$ is a chain
map $\rmd_B f^k(a) = \rmd_B b$, thus:
\begin{align*}
\rmd_B(b - f^k(a)) = 0
\end{align*}
Hence $[c] \in \Img(g^k)$ and especially $\Img(g^*) = \ker (\rmd^*)$.

The last step is to proof that $\Img(\mathrm{d}^*) = \ker(f^*)$. Let $[c] \in H^k(C^*)$, then
$f^{k + 1}(\rmd^* c) = [\rmd_B b]$ for some $b \in H^k(B^*)$ by construction, hence
$\Img(\mathrm{d}^*) \subseteq \ker(f^*)$. The reverse works similiar, if
$[a] \in \ker(f^{k + 1})$ then there is a $b \in B^k$ such that
$f^{k + 1}(a) = \rmd_B^{k + 1}b$, then by our construction $\rmd^*([g^{k}(b)]) = [a]$ and
therefore $\Img(\rmd^*) = \ker(f^*)$.
\end{proof}

It is constructive to translate this result back into the language of de Rham cohomology
using a concrete example. Let us look at the circle $S^1$ and compute its cohomology
using this sequence. We can cover $S^1$ by two open sets $\U, \V$ as seen in TODO, then
$H^0(\U \cap \V) \simeq \RR^2$ by TODO and $H^k(\U) = H^k(\V) = H^k(\U \cap \V) = 0$ for
every $k \geq 1$ by TODO. Thus we get the sequence:
% https://q.uiver.app/#q=WzAsNixbMCwwLCIwIl0sWzEsMCwiSF4wKFNeMSkiXSxbMiwwLCJIXjAoXFxVKSBcXG9wbHVzIEheMChcXFYpIl0sWzMsMCwiSF4wKFxcVSBcXGNhcCBcXFYpIl0sWzQsMCwiSF4xKFNeMSkiXSxbNSwwLCIwIl0sWzAsMV0sWzEsMl0sWzIsM10sWzMsNF0sWzQsNV1d
\[\begin{tikzcd}[column sep=small]
	0 & {H^0(S^1)} & {H^0(\U) \oplus H^0(\V)} & {H^0(\U \cap \V)} & {H^1(S^1)} & 0
	\arrow[from=1-1, to=1-2]
	\arrow[from=1-2, to=1-3]
	\arrow[from=1-3, to=1-4]
	\arrow[from=1-4, to=1-5]
	\arrow[from=1-5, to=1-6]
\end{tikzcd}\]
It is already known that $H^0(S^1)$ consists of the const functions on $S^1$ (since $S^1$
is connected) and the restriction of these functions are obviously const themselves
% TODO: First algebraic, then geometric
% TODO: Some computational examples

